{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import warnings\n",
    "from glob import glob\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import shap\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cbt\n",
    "import datetime as dt\n",
    "import statistics\n",
    "import random\n",
    "import eli5\n",
    "from pyti.ichimoku_cloud import tenkansen, kijunsen, chiku_span, senkou_a, senkou_b\n",
    "from pyti.bollinger_bands import upper_bollinger_band, middle_bollinger_band, lower_bollinger_band, bandwidth, percent_bandwidth, range\n",
    "from pyti.relative_strength_index import relative_strength_index\n",
    "from pyti.exponential_moving_average import exponential_moving_average\n",
    "from pyti.weighted_moving_average import weighted_moving_average\n",
    "from pyti.volume_adjusted_moving_average import volume_adjusted_moving_average\n",
    "from pyti.moving_average_convergence_divergence import moving_average_convergence_divergence\n",
    "from pyti.stochastic import percent_d, percent_k\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.ensemble import (\n",
    "    ExtraTreesRegressor,\n",
    "    GradientBoostingRegressor,\n",
    "    RandomForestRegressor,\n",
    ")\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from tqdm.auto import tqdm\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "pd.options.display.max_rows = 100\n",
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.width = 120"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir=\"../input\"\n",
    "inputs = {\n",
    "    \"stock_list\": f\"{dataset_dir}/stock_list.csv.gz\",\n",
    "    \"stock_price\": f\"{dataset_dir}/stock_price.csv.gz\",\n",
    "    \"stock_fin\": f\"{dataset_dir}/stock_fin.csv.gz\",\n",
    "    # \"stock_fin_price\": f\"{dataset_dir}/stock_fin_price.csv\",\n",
    "    \"stock_labels\": f\"{dataset_dir}/stock_labels.csv.gz\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {}\n",
    "for k, v in inputs.items():\n",
    "    dfs[k] = pd.read_csv(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_END = \"2018-12-31\"\n",
    "VAL_START = \"2019-01-01\"\n",
    "VAL_END = \"2019-12-31\"\n",
    "TEST_START = \"2020-01-01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Developing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_list = dfs[\"stock_list\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_list = stock_list[[\"Local Code\", \"33 Sector(name)\", \"17 Sector(name)\", \"IssuedShareEquityQuote IssuedShare\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_for_predict(dfs, code):\n",
    "    ################## stock_fin_feat ##################\n",
    "    # stock_finデータを読み込み\n",
    "    stock_fin = dfs[\"stock_fin\"].copy()\n",
    "\n",
    "    # 特定の銘柄コードのデータに絞る\n",
    "    fin_data = stock_fin[stock_fin[\"Local Code\"] == code].copy()\n",
    "    \n",
    "    # 業界データと結合\n",
    "    stock_list = dfs[\"stock_list\"].copy()\n",
    "    fin_list = stock_list[[\"Local Code\", \"33 Sector(name)\", \"17 Sector(name)\", \"IssuedShareEquityQuote IssuedShare\"]].copy()\n",
    "    fin_data = pd.merge(fin_data, fin_list, how=\"left\", on=\"Local Code\")\n",
    "        \n",
    "    # 日付列をpd.Timestamp型に変換してindexに設定\n",
    "    fin_data[\"datetime\"] = pd.to_datetime(fin_data[\"base_date\"])\n",
    "    fin_data.set_index(\"datetime\", inplace=True)\n",
    "    \n",
    "    # fin_dataのnp.float64のデータのみを取得\n",
    "    fin_data = fin_data.select_dtypes(include=[\"float64\"])\n",
    "    \n",
    "    # 企業\n",
    "    ## 営業利益率\n",
    "    fin_data[\"Rate_Operating_Margin\"] = fin_data[\"Result_FinancialStatement OperatingIncome\"] / fin_data[\"Result_FinancialStatement NetSales\"] * 100\n",
    "    ## 経常利益率\n",
    "    fin_data[\"Rate_Ordinary_Margin\"] = fin_data[\"Result_FinancialStatement OrdinaryIncome\"] / fin_data[\"Result_FinancialStatement NetSales\"] * 100\n",
    "    ## 純利益率\n",
    "    fin_data[\"Rate_Ordinary_Margin\"] = fin_data[\"Result_FinancialStatement NetIncome\"] / fin_data[\"Result_FinancialStatement NetSales\"] * 100\n",
    "    ## 売上成長率\n",
    "    fin_data[\"Rate_Grow_NetSales\"] = fin_data[\"Result_FinancialStatement NetSales\"].pct_change(4)\n",
    "    ## 営業利益成長率\n",
    "    fin_data[\"Rate_Grow_Operating\"] = fin_data[\"Result_FinancialStatement OperatingIncome\"].pct_change(4)\n",
    "    ## 経常利益成長率\n",
    "    fin_data[\"Rate_Grow_Ordinary\"] = fin_data[\"Result_FinancialStatement OrdinaryIncome\"].pct_change(4)\n",
    "    ## 純利益成長率\n",
    "    fin_data[\"Rate_Grow_NetIncome\"] = fin_data[\"Result_FinancialStatement NetIncome\"].pct_change(4)   \n",
    "    ## ROE\n",
    "    fin_data[\"ROE\"] = fin_data[\"Result_FinancialStatement NetIncome\"] / fin_data[\"Result_FinancialStatement NetAssets\"] * 100\n",
    "    ## ROA\n",
    "    fin_data[\"ROA\"] = fin_data[\"Result_FinancialStatement NetIncome\"] / fin_data[\"Result_FinancialStatement TotalAssets\"] * 100\n",
    "    ## EPS\n",
    "    fin_data[\"EPS\"] = fin_data[\"Result_FinancialStatement NetIncome\"] / fin_data[\"IssuedShareEquityQuote IssuedShare\"] * 100\n",
    "    ## BPS\n",
    "    fin_data[\"BPS\"] = fin_data[\"Result_FinancialStatement TotalAssets\"] / fin_data[\"IssuedShareEquityQuote IssuedShare\"]\n",
    "    ## ROE成長率\n",
    "    fin_data[\"Rate_Grow_ROE\"] = fin_data[\"ROE\"].pct_change(4)\n",
    "    ## ROA成長率\n",
    "    fin_data[\"Rate_Grow_ROA\"] = fin_data[\"ROA\"].pct_change(4)\n",
    "    ## 負債比率\n",
    "    fin_data[\"Result_FinancialStatement Liability\"] = fin_data[\"Result_FinancialStatement TotalAssets\"] - fin_data[\"Result_FinancialStatement NetAssets\"]\n",
    "    fin_data[\"Rate Liability\"] = fin_data[\"Result_FinancialStatement Liability\"] / fin_data[\"Result_FinancialStatement NetAssets\"] * 100\n",
    "    ## 来季結果と今期予測の差異\n",
    "    fin_forecast = fin_data[[\"Forecast_FinancialStatement NetSales\", \"Forecast_FinancialStatement OperatingIncome\", \"Forecast_FinancialStatement OrdinaryIncome\", \"Forecast_FinancialStatement NetIncome\"]].diff(4)\n",
    "    fin_data[\"Diff Forecast Result NetSales\"] = fin_forecast[\"Forecast_FinancialStatement NetSales\"] / fin_data[\"Result_FinancialStatement NetSales\"] * 100\n",
    "    fin_data[\"Diff Forecast Result OperatingIncome\"] = fin_forecast[\"Forecast_FinancialStatement OperatingIncome\"] / fin_data[\"Result_FinancialStatement OperatingIncome\"] * 100\n",
    "    fin_data[\"Diff Forecast Result OrdinaryIncome\"] = fin_forecast[\"Forecast_FinancialStatement OrdinaryIncome\"] / fin_data[\"Result_FinancialStatement OrdinaryIncome\"] * 100\n",
    "    fin_data[\"Diff Forecast Result NetIncome\"] = fin_forecast[\"Forecast_FinancialStatement NetIncome\"] / fin_data[\"Result_FinancialStatement NetIncome\"] * 100\n",
    "    \n",
    "    # 欠損値処理\n",
    "    fin_feats = fin_data.fillna(0)\n",
    "\n",
    "    ################## stock_price_feat ##################\n",
    "    # stock_priceデータを読み込む\n",
    "    price = dfs[\"stock_price\"].copy()\n",
    "\n",
    "    # 特定の銘柄コードのデータに絞る\n",
    "    price_data = price[price[\"Local Code\"] == code].copy()\n",
    "    \n",
    "    # 日付列をpd.Timestamp型に変換してindexに設定\n",
    "    price_data[\"datetime\"] = pd.to_datetime(price_data[\"EndOfDayQuote Date\"])\n",
    "    price_data.set_index(\"datetime\", inplace=True)\n",
    "    \n",
    "    # 終値, ボリューム\n",
    "    feats = price_data[[\"EndOfDayQuote ExchangeOfficialClose\", \"EndOfDayQuote Volume\"]].copy()\n",
    "\n",
    "    # 終値の20営業日リターン\n",
    "    feats[\"return_1month\"] = feats[\"EndOfDayQuote ExchangeOfficialClose\"].pct_change(20)\n",
    "    # 終値と20営業日の単純移動平均線の乖離\n",
    "    feats[\"MA_gap_1month\"] = feats[\"EndOfDayQuote ExchangeOfficialClose\"] / (feats[\"EndOfDayQuote ExchangeOfficialClose\"].rolling(20).mean())\n",
    "    # 終値と20営業日の単純移動平均線の乖離\n",
    "    feats[\"EMA_gap_1month\"] = feats[\"EndOfDayQuote ExchangeOfficialClose\"] / (feats[\"EndOfDayQuote ExchangeOfficialClose\"].ewm(span=20).mean())    \n",
    "    # 過去20営業日の平均売買金額\n",
    "    feats[\"Volume_mean_1month\"] = feats[\"EndOfDayQuote Volume\"].rolling(window=20).mean()\n",
    "    \n",
    "    # RSI\n",
    "    feats[\"rsi\"] = relative_strength_index(feats[\"EndOfDayQuote ExchangeOfficialClose\"], period=20)\n",
    "    # feats[\"rsi_under_30\"] = feats[\"rsi\"] < 30\n",
    "    # feats[\"rsi_over_70\"] = feats[\"rsi\"] > 70\n",
    "        \n",
    "    # テクニカル指標\n",
    "      # ラグファクター\n",
    "      # トレンドライン、サポートライン、レジスタンスライン\n",
    "\n",
    "    # おおまかな手順の3つ目\n",
    "    # 欠損値処理\n",
    "    feats = feats.fillna(0)\n",
    "\n",
    "    # 財務データの特徴量とマーケットデータの特徴量のインデックスを合わせる\n",
    "    feats = feats.loc[feats.index.isin(fin_feats.index)]\n",
    "    fin_feats = fin_feats.loc[fin_feats.index.isin(feats.index)]\n",
    "    \n",
    "    # データを結合\n",
    "    feats = pd.concat([feats, fin_feats], axis=1).dropna()    \n",
    "    \n",
    "    ################## stock_fin&price_feat ##################\n",
    "    ## 時価総額\n",
    "    feats[\"Market Capitalization\"] = feats[\"IssuedShareEquityQuote IssuedShare\"] * feats[\"EndOfDayQuote ExchangeOfficialClose\"]\n",
    "    ## PER\n",
    "    feats[\"PER\"] = feats[\"EndOfDayQuote ExchangeOfficialClose\"] / feats[\"EPS\"]\n",
    "    ## PBR\n",
    "    feats[\"PBR\"] = feats[\"EndOfDayQuote ExchangeOfficialClose\"] / feats[\"BPS\"]\n",
    "\n",
    "    # 元データのカラムを削除\n",
    "    feats = feats.drop([\"EndOfDayQuote ExchangeOfficialClose\"], axis=1)\n",
    "\n",
    "    # 欠損値処理を行います。\n",
    "    feats = feats.replace([np.inf, -np.inf], 0)\n",
    "\n",
    "    # 銘柄コードを設定\n",
    "    feats[\"code\"] = code\n",
    "\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_and_label(dfs, codes, feature, label):\n",
    "   # 分割データ用の変数を定義\n",
    "    trains_X, vals_X, tests_X = [], [], []\n",
    "    trains_y, vals_y, tests_y = [], [], []\n",
    "\n",
    "    # 銘柄コード毎に特徴量を作成\n",
    "    for code in tqdm(codes):\n",
    "        # 特徴量取得\n",
    "        feats = feature[feature[\"code\"] == code]\n",
    "\n",
    "        # stock_labelデータを読み込み\n",
    "        stock_labels = dfs[\"stock_labels\"].copy()\n",
    "        # 特定の銘柄コードのデータに絞る\n",
    "        stock_labels = stock_labels[stock_labels[\"Local Code\"] == code]\n",
    "        # 日付列をpd.Timestamp型に変換してindexに設定\n",
    "        stock_labels[\"datetime\"] = pd.to_datetime(stock_labels[\"base_date\"])\n",
    "        stock_labels.set_index(\"datetime\", inplace=True)\n",
    "\n",
    "        # 特定の目的変数に絞る\n",
    "        labels = stock_labels[label]\n",
    "        # nanを削除\n",
    "        labels.dropna(inplace=True)\n",
    "\n",
    "        if feats.shape[0] > 0 and labels.shape[0] > 0:\n",
    "            # 特徴量と目的変数のインデックスを合わせる\n",
    "            labels = labels.loc[labels.index.isin(feats.index)]\n",
    "            feats = feats.loc[feats.index.isin(labels.index)]\n",
    "            labels.index = feats.index\n",
    "\n",
    "            # データを分割（ホールドアウト法）\n",
    "            _train_X = feats[: TRAIN_END].copy()\n",
    "            _val_X = feats[VAL_START : VAL_END].copy()\n",
    "            _test_X = feats[TEST_START :].copy()\n",
    "\n",
    "            _train_y = labels[: TRAIN_END].copy()\n",
    "            _val_y = labels[VAL_START : VAL_END].copy()\n",
    "            _test_y = labels[TEST_START :].copy()\n",
    "\n",
    "            # データを配列に格納 (後ほど結合するため)\n",
    "            trains_X.append(_train_X)\n",
    "            vals_X.append(_val_X)\n",
    "            tests_X.append(_test_X)\n",
    "\n",
    "            trains_y.append(_train_y)\n",
    "            vals_y.append(_val_y)\n",
    "            tests_y.append(_test_y)\n",
    "\n",
    "    # 銘柄毎に作成した説明変数データを結合します。\n",
    "    train_X = pd.concat(trains_X)\n",
    "    val_X = pd.concat(vals_X)\n",
    "    test_X = pd.concat(tests_X)\n",
    "    \n",
    "    # 銘柄毎に作成した目的変数データを結合します。\n",
    "    train_y = pd.concat(trains_y)\n",
    "    val_y = pd.concat(vals_y)\n",
    "    test_y = pd.concat(tests_y)\n",
    "\n",
    "    return train_X, train_y, val_X, val_y, test_X, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_codes(dfs):\n",
    "    stock_list = dfs[\"stock_list\"].copy()\n",
    "    # 予測対象の銘柄コードを取得\n",
    "    codes = stock_list[stock_list[\"prediction_target\"] == True][\"Local Code\"].values\n",
    "    rondom_list = []\n",
    "    for k in range(150):\n",
    "        # x = random.randint(1,len(codes)-1)\n",
    "        rondom_list.append(k)\n",
    "    \n",
    "    limit_codes = codes[rondom_list]\n",
    "    \n",
    "    return limit_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(dfs, codes, label):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        dfs (dict)  : dict of pd.DataFrame include stock_fin, stock_price\n",
    "        codes (list[int]): A local code for a listed company\n",
    "        label (str): prediction target label\n",
    "    Returns:\n",
    "         RandomForestRegressor\n",
    "    \"\"\"\n",
    "    # 特徴量を取得\n",
    "    buff = []\n",
    "    for code in codes:\n",
    "        buff.append(get_features_for_predict(dfs, code))\n",
    "    feature = pd.concat(buff)\n",
    "    \n",
    "    # 特徴量と目的変数を一致させて、データを分割\n",
    "    train_X, train_y, val_X, val_y, test_X, test_y = get_features_and_label(\n",
    "            dfs, codes, feature, label\n",
    "    )\n",
    "    \n",
    "    train_X = pd.concat([train_X, val_X])\n",
    "    train_y = pd.concat([train_y, val_y])\n",
    "    \n",
    "    # 不要な特徴を削除\n",
    "    drop_col = [\"code\", \"Result_FinancialStatement FiscalYear\",\n",
    "                \"Result_Dividend FiscalYear\",\n",
    "                \"Result_FinancialStatement TotalAssets\",\n",
    "                \"Result_FinancialStatement NetAssets\",\n",
    "                \"Result_FinancialStatement Liability\",\n",
    "                \"Forecast_Dividend FiscalYear\",\n",
    "                \"Result_FinancialStatement CashFlowsFromFinancingActivities\",\n",
    "                \"Result_FinancialStatement CashFlowsFromInvestingActivities\",\n",
    "                \"Result_FinancialStatement CashFlowsFromOperatingActivities\",\n",
    "                \"Forecast_FinancialStatement FiscalYear\"]\n",
    "    train_X = train_X.drop(drop_col, axis=1)\n",
    "    test_X = test_X.drop(drop_col, axis=1)\n",
    "    \n",
    "    # モデル作成\n",
    "    spear = []\n",
    "    rmse = []\n",
    "    model_feature = []\n",
    "    \n",
    "    period_list = [\"2016-07-01\",\"2017-07-01\", \"2018-07-01\"]\n",
    "    for idx, period in enumerate(period_list):\n",
    "        period_tr_end = dt.date(int(period[0:4])+1, int(period[5:7])-4, int(period[8:10])+24)\n",
    "        period_va_start = dt.date(int(period[0:4])+1, int(period[5:7])-4, int(period[8:10])+25)\n",
    "        period_va_end = dt.date(int(period[0:4])+1, int(period[5:7])-1, int(period[8:10])+10)\n",
    "\n",
    "        is_tr = (train_X.index > period) & (train_X.index < period_tr_end.strftime('%Y-%m-%d'))\n",
    "        is_va = (train_X.index > period_va_start.strftime('%Y-%m-%d')) & (train_X.index < period_va_end.strftime('%Y-%m-%d'))\n",
    "\n",
    "        model = lgb.LGBMRegressor(random_state=0, n_estimators=300)\n",
    "        model.fit(train_X[is_tr], train_y[is_tr],\n",
    "                  eval_set=[(train_X[is_va], train_y[is_va])],\n",
    "                  eval_metric='rmse',\n",
    "                  eval_names=[('train_set', 'eval_set')],\n",
    "                  early_stopping_rounds=20,\n",
    "                  verbose=300)\n",
    "        \n",
    "        pred_y= model.predict(test_X)\n",
    "        \n",
    "        spear.append(spearmanr(test_y, pred_y)[0])\n",
    "        rmse.append(np.sqrt(mean_squared_error(test_y, pred_y)))\n",
    "        model_feature.append(model.feature_importances_)\n",
    "\n",
    "    print(\"============= final result =============\")\n",
    "    print(\"spear : \" + str(spear))\n",
    "    print(\"rmse : \" + str(rmse))\n",
    "    print(\"============= final mean result =============\")\n",
    "    print(\"spear_means : \" + str(statistics.mean(spear)))\n",
    "    print(\"rmse_means : \" + str(statistics.mean(rmse)))\n",
    "    \n",
    "    return model,train_X, model_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = get_codes(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model,train_X, model_feature = create_model(dfs, codes, label=\"label_high_20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(np.average(model_feature, axis = 0), index=train_X.columns, columns=['importance']).sort_values('importance',  ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP値\n",
    "shap.initjs()\n",
    "explainer = shap.TreeExplainer(model=model, feature_perturbation='tree_path_dependent', model_output='margin')\n",
    "shap_values = explainer.shap_values(X=train_X)\n",
    "shap.summary_plot(shap_values, train_X, plot_type=\"bar\", max_display=train_X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# eli5\n",
    "eli5.explain_weights(model, top=100, importance_type='gain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "period_list = [\"2016-07-01\",\"2017-07-01\", \"2018-07-01\"]\n",
    "for idx, period in enumerate(period_list):\n",
    "    period_tr_end = dt.date(int(period[0:4])+1, int(period[5:7])-4, int(period[8:10])+24)\n",
    "    period_va_start = dt.date(int(period[0:4])+1, int(period[5:7])-4, int(period[8:10])+25)\n",
    "    period_va_end = dt.date(int(period[0:4])+1, int(period[5:7])-1, int(period[8:10])+10)\n",
    "\n",
    "    is_tr = (train_X.index > period) & (train_X.index < period_tr_end.strftime('%Y-%m-%d'))\n",
    "    is_va = (train_X.index > period_va_start.strftime('%Y-%m-%d')) & (train_X.index < period_va_end.strftime('%Y-%m-%d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = 1301"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_list = dfs[\"stock_list\"].copy()\n",
    "fin_list = stock_list[stock_list[\"Local Code\"] == code][[\"Local Code\", \"33 Sector(name)\", \"17 Sector(name)\", \"IssuedShareEquityQuote IssuedShare\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_fin = dfs[\"stock_fin\"].copy()\n",
    "fin_data = stock_fin[stock_fin[\"Local Code\"] == code].copy()\n",
    "fin_data = pd.merge(fin_data, fin_list, how=\"left\", on=\"Local Code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_price = dfs[\"stock_price\"].copy()\n",
    "price_data = stock_price[stock_price[\"Local Code\"] == code].copy()\n",
    "price_data = pd.merge(price_data, fin_list, how=\"left\", on=\"Local Code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_sector33_mean = fin_data.groupby([\"33 Sector(name)\",\"Result_FinancialStatement ReportType\"]).mean()[[\"Result_FinancialStatement NetSales\", \"Result_FinancialStatement OperatingIncome\", \"Result_FinancialStatement OrdinaryIncome\", \"Result_FinancialStatement NetIncome\"]].reset_index()\n",
    "fin_sector33_mean.columns = [\"33 Sector(name)\", \"Result_FinancialStatement ReportType\",\n",
    "                             \"Result_FinancialStatement NetSales_33mean\", \n",
    "                             \"Result_FinancialStatement OperatingIncome_33mean\",\n",
    "                             \"Result_FinancialStatement OrdinaryIncome_33mean\",\n",
    "                             \"Result_FinancialStatement NetIncome_33mean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_sector17_mean = fin_data.groupby([\"17 Sector(name)\", \"Result_FinancialStatement ReportType\"]).mean()[[\"Result_FinancialStatement NetSales\", \"Result_FinancialStatement OperatingIncome\", \"Result_FinancialStatement OrdinaryIncome\", \"Result_FinancialStatement NetIncome\"]].reset_index()\n",
    "fin_sector17_mean.columns = [\"17 Sector(name)\", \"Result_FinancialStatement ReportType\",\n",
    "                             \"Result_FinancialStatement NetSales_17mean\", \n",
    "                             \"Result_FinancialStatement OperatingIncome_17mean\",\n",
    "                             \"Result_FinancialStatement OrdinaryIncome_17mean\",\n",
    "                             \"Result_FinancialStatement NetIncome_17mean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_data = pd.merge(fin_data, fin_sector17_mean, how=\"left\", on=[\"17 Sector(name)\", \"Result_FinancialStatement ReportType\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_data = pd.merge(fin_data, fin_sector33_mean, how=\"left\", on=[\"33 Sector(name)\", \"Result_FinancialStatement ReportType\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create_model Backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(dfs, codes, label):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        dfs (dict)  : dict of pd.DataFrame include stock_fin, stock_price\n",
    "        codes (list[int]): A local code for a listed company\n",
    "        label (str): prediction target label\n",
    "    Returns:\n",
    "         RandomForestRegressor\n",
    "    \"\"\"\n",
    "    # 特徴量を取得\n",
    "    buff = []\n",
    "    for code in codes:\n",
    "        buff.append(get_features_for_predict(dfs, code))\n",
    "    feature = pd.concat(buff)\n",
    "    \n",
    "    # 特徴量と目的変数を一致させて、データを分割\n",
    "    train_X, train_y, val_X, val_y, test_X, test_y = get_features_and_label(\n",
    "            dfs, codes, feature, label\n",
    "    )\n",
    "    \n",
    "    train_X = pd.concat([train_X, val_X])\n",
    "    train_y = pd.concat([train_y, val_y])\n",
    "    \n",
    "    # 不要な特徴を削除\n",
    "    drop_col = [\"code\", \"Result_FinancialStatement FiscalYear\",\n",
    "                \"Result_Dividend FiscalYear\",\n",
    "                \"Result_FinancialStatement TotalAssets\",\n",
    "                \"Result_FinancialStatement NetAssets\",\n",
    "                \"Result_FinancialStatement Liability\",\n",
    "                \"Result_FinancialStatement NetSales_17mean\",\n",
    "                \"Result_FinancialStatement OperatingIncome_17mean\",\n",
    "                \"Result_FinancialStatement OrdinaryIncome_17mean\",\n",
    "                \"Result_FinancialStatement NetIncome_17mean\",\n",
    "                \"Result_FinancialStatement NetSales_33mean\",\n",
    "                \"Result_FinancialStatement OperatingIncome_33mean\",\n",
    "                \"Result_FinancialStatement OrdinaryIncome_33mean\",\n",
    "                \"Result_FinancialStatement NetIncome_33mean\",\n",
    "                \"Forecast_FinancialStatement FiscalYear\"]\n",
    "    train_X = train_X.drop(drop_col, axis=1)\n",
    "    test_X = test_X.drop(drop_col, axis=1)\n",
    "    \n",
    "    # モデル作成\n",
    "    spear = []\n",
    "    rmse = []\n",
    "    r2 = []\n",
    "    # TRAIN_END = \"2017-12-31\" VAL_START = \"2018-02-01\" VAL_END = \"2018-12-01\" TEST_START = \"2019-01-01\"\n",
    "    for mdl in [lgb.LGBMRegressor(random_state=0)]:\n",
    "        model = mdl\n",
    "        model.fit(train_X, train_y)\n",
    "        pred_y= model.predict(test_X)\n",
    "        \n",
    "        spear.append(spearmanr(test_y, pred_y)[0])\n",
    "        rmse.append(np.sqrt(mean_squared_error(test_y, pred_y)))\n",
    "        r2.append(r2_score(test_y, pred_y))\n",
    "        \n",
    "    # print(spear)\n",
    "    print(\"spear_means : \" + str(statistics.mean(spear)))\n",
    "    print(\"rmse_means : \" + str(statistics.mean(rmse)))\n",
    "    print(\"r2_means : \" + str(statistics.mean(r2)))\n",
    "    \n",
    "    return model,train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from predictor import ScoringService"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセットを取得\n",
    "DATASET_DIR= \"../input\"\n",
    "inputs = ScoringService.get_inputs(DATASET_DIR)\n",
    "dfs = ScoringService.get_dataset(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 対象コードを取得\n",
    "codes = ScoringService.get_codes(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddfec052bc2c456faf26ae47454041a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3523.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59e56a6983b74a1bbfad2df5d6f17594",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3523.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for label in [\"label_high_20\", \"label_low_20\"]:\n",
    "    model = ScoringService.create_model(dfs=dfs, codes=codes, label=label)\n",
    "    ScoringService.save_model(model=model, label=label, model_path=\"../model/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 対象の目的変数を定義\n",
    "labels = {\"label_high_20\", \"label_low_20\"}\n",
    "ScoringService.get_model(model_path=\"../model/\", labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ScoringService.predict(inputs=inputs, labels=labels, codes=codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ScoringService.get_model()  # モデルの取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ScoringService.predict(inputs=inputs, codes=codes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
